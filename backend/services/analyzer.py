from typing import Optional
import json
from .metrics import analyze_metrics
from .gemini_client import get_summary, get_comments

def run_analysis(code: str, features: dict, mode: str = "local", api_key: Optional[str] = None):
    """
    Orchestrate analysis. Always runs local static metrics.
    If mode == "cloud" and api_key provided, use Gemini for summary/comments.
    """
    results = {}

    # Always compute local metrics
    if features.get("metrics", True):
        results["metrics"] = analyze_metrics(code)

    # LLM-backed features
    if mode == "cloud" and api_key:
        if features.get("summary", True):
            results["summary"] = get_summary(code, api_key=api_key)

        if features.get("review", True):
            comments_text = get_comments(code, results.get("metrics", {}), api_key=api_key)
            try:
                results["comments"] = json.loads(comments_text)
            except Exception:
                results["comments_raw"] = comments_text

        if features.get("tags", True):
            # simple heuristic tags; can be replaced by LLM tagging call
            tags = []
            mi = results.get("metrics", {}).get("mi_avg")
            cc = results.get("metrics", {}).get("cc_avg")
            if cc and cc > 10:
                tags.append("Performance")
            if mi and mi < 60:
                tags.append("Readability")
            results["tags"] = tags

        if features.get("docs", True):
            results["docs"] = ["Library docs will be generated by LLM (placeholder)"]

    return results
